{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6165fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1단계: 각 공장별 EPC 코드 샘플링 시작 ---\n",
      "'../DB/icn.csv' 파일 처리 중...\n",
      "  - 고유 EPC 수: 100000\n",
      "  - 샘플링할 EPC 수 (20.0%): 20000\n",
      "'../DB/hws.csv' 파일 처리 중...\n",
      "  - 고유 EPC 수: 50000\n",
      "  - 샘플링할 EPC 수 (20.0%): 10000\n",
      "'../DB/kum.csv' 파일 처리 중...\n",
      "  - 고유 EPC 수: 20000\n",
      "  - 샘플링할 EPC 수 (20.0%): 4000\n",
      "'../DB/ygs.csv' 파일 처리 중...\n",
      "  - 고유 EPC 수: 30000\n",
      "  - 샘플링할 EPC 수 (20.0%): 6000\n",
      "\n",
      "--- 1단계 완료 ---\n",
      "모든 공장에서 샘플링된 총 고유 EPC 코드 수: 40000\n",
      "\n",
      "--- 2단계: 샘플링된 EPC에 해당하는 전체 이력 추출 시작 (메모리 최적화 적용) ---\n",
      "'../DB/icn.csv' 파일에서 데이터 분할 로딩 중...\n",
      "'../DB/hws.csv' 파일에서 데이터 분할 로딩 중...\n",
      "'../DB/kum.csv' 파일에서 데이터 분할 로딩 중...\n",
      "'../DB/ygs.csv' 파일에서 데이터 분할 로딩 중...\n",
      "\n",
      "--- 2단계 완료 ---\n",
      "최종 추출된 데이터 행(row) 수: 184602\n",
      "\n",
      "✅ 완료: 모든 데이터가 'dataSet\\factory_20pct_data.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # <<< [추가] 파일 및 폴더 관리를 위해 os 모듈 임포트\n",
    "\n",
    "# 1. 처리할 공장 CSV 파일 목록과 샘플링 비율 설정\n",
    "factory_files = [\n",
    "    '../DB/icn.csv', \n",
    "    '../DB/hws.csv', \n",
    "    '../DB/kum.csv', \n",
    "    '../DB/ygs.csv'\n",
    "]\n",
    "# sampling_ratio = 1 로 설정하셨으므로, 사실상 모든 EPC를 추출하여 합치는 것과 같습니다.\n",
    "# 이는 전체 데이터를 통합하는 올바른 방법입니다.\n",
    "sampling_ratio = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "# 2. 각 공장 파일에서 샘플링할 EPC 코드를 저장할 리스트\n",
    "sampled_epc_codes = []\n",
    "\n",
    "print(\"--- 1단계: 각 공장별 EPC 코드 샘플링 시작 ---\")\n",
    "\n",
    "for file in factory_files:\n",
    "    try:\n",
    "        print(f\"'{file}' 파일 처리 중...\")\n",
    "        df_epc_only = pd.read_csv(file, usecols=['epc_code'], dtype=str)\n",
    "        unique_epcs = df_epc_only['epc_code'].unique()\n",
    "        \n",
    "        n_samples = int(len(unique_epcs) * sampling_ratio)\n",
    "        if n_samples == 0 and len(unique_epcs) > 0:\n",
    "            n_samples = 1\n",
    "        \n",
    "        print(f\"  - 고유 EPC 수: {len(unique_epcs)}\")\n",
    "        print(f\"  - 샘플링할 EPC 수 ({sampling_ratio*100}%): {n_samples}\")\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        sampled_list = np.random.choice(unique_epcs, size=n_samples, replace=False).tolist()\n",
    "        sampled_epc_codes.extend(sampled_list)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"경고: '{file}' 파일을 찾을 수 없습니다. 건너뜁니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류: '{file}' 처리 중 문제 발생 - {e}\")\n",
    "\n",
    "final_sampled_epcs = list(set(sampled_epc_codes))\n",
    "print(\"\\n--- 1단계 완료 ---\")\n",
    "print(f\"모든 공장에서 샘플링된 총 고유 EPC 코드 수: {len(final_sampled_epcs)}\")\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# 3. [최적화] 샘플링된 EPC에 해당하는 모든 이력(row)을 메모리 효율적으로 추출\n",
    "# =================================================================\n",
    "print(\"\\n--- 2단계: 샘플링된 EPC에 해당하는 전체 이력 추출 시작 (메모리 최적화 적용) ---\")\n",
    "\n",
    "all_dataframes = []\n",
    "chunk_size = 100000  # 파일을 10만 줄씩 나누어 읽음\n",
    "\n",
    "for file in factory_files:\n",
    "    try:\n",
    "        print(f\"'{file}' 파일에서 데이터 분할 로딩 중...\")\n",
    "        # 파일을 chunk_size 만큼씩 나누어 읽는 반복자(iterator) 생성\n",
    "        for chunk in pd.read_csv(file, dtype=str, chunksize=chunk_size):\n",
    "            # 각 chunk(작은 DataFrame)에서 필요한 EPC에 해당하는 행만 필터링\n",
    "            filtered_chunk = chunk[chunk['epc_code'].isin(final_sampled_epcs)]\n",
    "            # 필터링된 결과만 리스트에 추가\n",
    "            if not filtered_chunk.empty:\n",
    "                all_dataframes.append(filtered_chunk)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"경고: '{file}' 파일을 다시 로드하는 중 찾을 수 없습니다.\")\n",
    "\n",
    "# 모든 필터링된 DataFrame 조각들을 하나로 합칩니다.\n",
    "if all_dataframes:\n",
    "    final_sample_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "else:\n",
    "    final_sample_df = pd.DataFrame()\n",
    "\n",
    "print(\"\\n--- 2단계 완료 ---\")\n",
    "print(f\"최종 추출된 데이터 행(row) 수: {len(final_sample_df)}\")\n",
    "\n",
    "# =================================================================\n",
    "# 4. 결과를 'dataSet' 폴더 안에 저장\n",
    "# =================================================================\n",
    "if not final_sample_df.empty:\n",
    "    output_folder = 'dataSet'\n",
    "    output_filename = 'factory_20pct_data.csv' # sampling_ratio=1이므로 모든 데이터를 의미하는 이름으로 변경\n",
    "    \n",
    "    # 폴더가 없으면 생성\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # 최종 파일 경로 생성 (폴더 + 파일명)\n",
    "    full_path = os.path.join(output_folder, output_filename)\n",
    "    \n",
    "    final_sample_df.to_csv(full_path, index=False)\n",
    "    print(f\"\\n✅ 완료: 모든 데이터가 '{full_path}' 파일로 저장되었습니다.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 경고: 추출된 데이터가 없어 파일을 생성하지 않았습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
