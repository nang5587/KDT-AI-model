# 📈 LTA-Detector: 모델 성능 실험 기록

이 문서는 물류 추적 이상 탐지(Logistics Trace Anomaly Detector) 모델의 하이퍼파라미터 튜닝 및 성능 개선 과정을 기록합니다.

## 🎯 프로젝트 목표

LSTM 기반의 다중 입력 오토인코더를 사용하여 물류 데이터 시퀀스의 정상 패턴을 학습하고, 이를 통해 비정상적인 물류 이동을 실시간으로 탐지하는 것을 목표로 합니다.

## 📊 실험 결과 요약 (Summary Table)

모든 실험의 핵심 성능 지표를 비교합니다. 현재까지 가장 우수한 성능을 보인 실험은 **굵게** 표시합니다.

| 실험 ID | 날짜 | 주요 변경점 / 실험 내용 | AUC | Recall (A) | Precision (A) | F1-Score (A) | 커밋 해시 |
| :--- | :--- | :--- | :---: | :---: | :---: | :---: | :--- |
| exp-20250815-141604 | 25/08/15 | LSTM_UNITS 64 | 0.784 | 0.60 | 0.94 | 0.73 | `a466223` |
| exp-20250815-123912 | 25/08/15 | EMBEDDING_DIM 16, LATENT_DIM 16, EPOCHS 200 성능 측정 | 0.780 | 0.59 | 0.91 | 0.72 | `450adff` |
| exp-20250815-114645 | 25/08/15 | [ALL]EMBEDDING_DIM 16, LATENT_DIM 16 성능 측정 | 0.791 | 0.61 | 0.93 | 0.74 | `450adff` |
| exp-20250815-104524 | 25/08/15 | EMBEDDING_DIM 32, LATENT_DIM 8 성능 측정 | 0.780 | 0.61 | 0.92 | 0.73 | `450adff` |
| exp-20250815-103135 | 25/08/15 | EMBEDDING_DIM 64, LATENT_DIM 16 성능 측정 | 0.792 | 0.61 | 0.94 | 0.74 | `450adff` |
| exp-20250814-192539 | 25/08/14 | EMBEDDING_DIM 32, LATENT_DIM 16 성능 측정 | 0.790 | 0.61 | 0.94 | 0.74 | `450adff` |
| **exp-20250814-182752** | 25/08/14 | LATENT_DIM 16 성능 측정 | 0.787 | 0.62 | 0.90 | 0.74 | `450adff` |
| exp-20250814-181431 | 25/08/14 | LATENT_DIM 4 성능 측정 | 0.788 | 0.62 | 0.88 | 0.73 | `450adff` |
| exp-20250814-175958 | 25/08/14 | EMBEDDING_DIM 32 성능 측정 | 0.787 | 0.62 | 0.92 | 0.74 | `450adff` |
| exp-20250814-172309 | 25/08/14 | EMBEDDING_DIM 8 성능 측정 | 0.786 | 0.60 | 0.96 | 0.74 | `450adff` |
| exp-20250814-165527 | 25/08/14 | Baseline 모델, 초기 파라미터로 성능 측정 | 0.784 | 0.61 | 0.90 | 0.73 | `ffc7025` |

* `Recall(A)`, `Precision(A)`, `F1-Score(A)`: Anomaly(비정상) 클래스 기준 성능 지표입니다.

---

## 🔬 실험 상세 기록 (Detailed Logs)

각 실험의 가설, 방법, 결과 분석 및 결론을 상세히 기록합니다. (최신순으로 위에 추가)

### exp-20250815-141604: LSTM_UNITS 64 성능 측정 (25/08/15)
- **커밋 해시:** `a466223`
- **가설:** (여기에 이 실험을 왜 했는지 가설을 작성하세요)
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7844
  - Anomaly Recall: 0.6026 (비정상 데이터 중 60.3%를 탐지함)
  - Anomaly Precision: 0.9407 (비정상이라고 예측한 것 중 94.1%가 진짜 비정상)
- **결론:** (여기에 실험 결과에 대한 결론을 작성하세요)

---

### exp-20250815-123912: EMBEDDING_DIM 16, LATENT_DIM 16, EPOCHS 200 성능 측정 (25/08/15)
- **커밋 해시:** `450adff`
- **가설:** (여기에 이 실험을 왜 했는지 가설을 작성하세요)
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 200
- **결과 분석:**
  - AUC: 0.7797
  - Anomaly Recall: 0.5921 (비정상 데이터 중 59.2%를 탐지함)
  - Anomaly Precision: 0.9063 (비정상이라고 예측한 것 중 90.6%가 진짜 비정상)
- **결론:** (여기에 실험 결과에 대한 결론을 작성하세요)

---


### exp-20250815-114645: [ALL]EMBEDDING_DIM 16, LATENT_DIM 16 성능 측정 (25/08/15)
- **커밋 해시:** `450adff`
- **가설:** 20% 샘플 데이터에서 최적의 성능을 보였던 EMBEDDING_DIM=16, LATENT_DIM=16 하이퍼파라미터 조합을 전체 데이터셋(92만 행)으로 학습시키면, 모델이 훨씬 더 다양하고 광범위한 정상 패턴을 학습하게 될 것이다. 이 풍부한 학습 경험은 모델의 일반화 성능을 극대화하여, 샘플 데이터로 학습했을 때보다 모든 성능 지표, 특히 모델의 변별력(AUC)과 탐지율(Recall)을 유의미하게 향상시킬 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7911
  - Anomaly Recall: 0.6111 (비정상 데이터 중 61.1%를 탐지함)
  - Anomaly Precision: 0.9330 (비정상이라고 예측한 것 중 93.3%가 진짜 비정상)
- **결론:** 예상과 달리, 전체 데이터셋으로 학습했음에도 불구하고 성능이 샘플 데이터 학습 결과(AUC: 0.787, Recall: 0.622) 대비 크게 향상되지 않았다. 오히려 핵심 지표인 Anomaly Recall은 소폭 하락했다. 이는 몇 가지 가능성을 시사한다: 1) 현재의 모델 구조(LSTM 레이어 1개)로는 더 많은 데이터를 처리해도 학습할 수 있는 패턴의 복잡성에 한계가 있을 수 있다. 2) 20% 샘플 데이터가 이미 전체 데이터의 분포를 충분히 잘 대표하고 있었을 가능성. 3) 고정된 EPOCHS=50이 더 커진 데이터셋을 완전히 학습하기에 부족했을 수 있다. 비록 Precision이 0.933으로 매우 높게 나타났지만, Recall의 정체는 모델 구조 개선이나 더 긴 학습 시간 등 추가적인 실험의 필요성을 제기한다. 현재로서는 전체 데이터 학습의 이점이 명확하게 드러나지 않았다.

---

### exp-20250815-104524: EMBEDDING_DIM 32, LATENT_DIM 8 성능 측정 (25/08/15)
- **커밋 해시:** `450adff`
- **가설:** 이전 EMBEDDING_DIM=32 실험에서 높은 Precision을 확보했고, LATENT_DIM=8은 Baseline에서 안정적인 성능을 보였다. 이 두 파라미터를 조합하면, 높은 예측 신뢰도(Precision)를 유지하면서도 Recall 저하를 막아 가장 균형 잡힌 최적의 모델을 찾을 수 있을 것이라는 가설을 세운다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 32
  - `LATENT_DIM`: 8
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7801
  - Anomaly Recall: 0.6076 (비정상 데이터 중 60.8%를 탐지함)
  - Anomaly Precision: 0.9161 (비정상이라고 예측한 것 중 91.6%가 진짜 비정상)
- **결론:** 가설과 달리, 두 파라미터의 조합은 성능 하락으로 이어졌다. 특히 핵심 지표인 Anomaly Recall이 0.622(이전 최고)에서 0.608로 하락하여, 비정상 탐지 능력이 약화되었다. 이는 풍부한 표현력(EMBEDDING_DIM=32)을 가진 입력 정보를 상대적으로 너무 작은 병목 구간(LATENT_DIM=8)으로 압축하는 과정에서, 오히려 정상과 비정상을 구분하는 데 필요한 미세한 정보가 손실되었기 때문으로 추정된다. 따라서 이 조합은 최적화에 실패했으며, 현재까지는 EMBEDDING_DIM=16, LATENT_DIM=16 조합이 가장 우수한 성능을 보이는 것으로 재확인되었다.

---


### exp-20250815-103135: EMBEDDING_DIM 64, LATENT_DIM 16 성능 측정 (25/08/15)
- **커밋 해시:** `450adff`
- **가설:** 임베딩 차원을 64로 크게 확장함으로써 모델에 최대의 표현력을 부여한다. 이를 통해 모델은 location_id와 event_type 간의 매우 복잡하고 미묘한 상호작용까지 학습할 수 있게 될 것이다. 이처럼 정교해진 정상 패턴의 이해는, 정상 데이터의 복원 능력을 향상시키고 비정상 데이터와의 경계를 더욱 명확히 하여, 모델의 전반적인 변별력(AUC)과 예측 신뢰도(Precision)를 크게 향상시킬 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 64
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7920
  - Anomaly Recall: 0.6150 (비정상 데이터 중 61.5%를 탐지함)
  - Anomaly Precision: 0.9352 (비정상이라고 예측한 것 중 93.5%가 진짜 비정상)
- **결론:** 가설대로 AUC와 Anomaly Precision은 각각 0.792, 0.935로 이전 실험들보다 상승하며, 모델의 전반적인 변별력과 예측 신뢰도가 향상되었음을 확인했다. 하지만, 핵심 목표였던 Anomaly Recall은 0.622(이전 최고)에서 0.615로 오히려 소폭 하락했다. 이는 모델의 표현력이 너무 강력해져, 일부 애매한 비정상 패턴까지 '있을 법한 정상'의 범주로 학습하고 성공적으로 복원해냈을 가능성을 시사한다. 즉, 모델이 너무 똑똑해져서 비정상을 놓치는 "과적합(Overfitting)의 초기 징후"일 수 있다. 비록 Precision이 매우 높아졌지만, Recall의 하락은 이상 탐지 모델의 핵심 목표와 상충되므로, 이 조합은 최적이라고 보기 어렵다. 현재로서는 EMBEDDING_DIM=16, LATENT_DIM=16 조합이 여전히 가장 균형 잡힌 성능을 제공한다.

---


### exp-20250814-192539: EMBEDDING_DIM 32, LATENT_DIM 16 성능 측정 (25/08/14)
- **커밋 해시:** `450adff`
- **가설:** 이전 실험들에서 각각 가장 좋은 성능을 보였던 EMBEDDING_DIM=32와 LATENT_DIM=16 설정을 조합하면, 시너지 효과를 통해 모델 성능을 최적화할 수 있을 것이다. 즉, 향상된 표현력(Embedding)으로 입력 정보의 손실을 최소화하고, 확장된 병목 구간(Latent)으로 정상 패턴의 복잡성을 충분히 학습함으로써, 모든 성능 지표(AUC, Recall, Precision)가 종합적으로 가장 높은 수준에 도달할 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 32
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7903
  - Anomaly Recall: 0.6114 (비정상 데이터 중 61.1%를 탐지함)
  - Anomaly Precision: 0.9433 (비정상이라고 예측한 것 중 94.3%가 진짜 비정상)
- **결론:** 예상과 달리, 개별적으로 최적이었던 두 하이퍼파라미터의 조합이 시너지 효과를 내지 못했다. AUC는 0.790으로 소폭 상승했으나, 핵심 목표였던 Anomaly Recall은 0.622에서 0.611로 오히려 하락했다. 반면, Anomaly Precision은 0.943으로 매우 높게 나타나, 모델이 더 보수적으로 비정상을 판단하는 경향을 보였다. 이는 모델의 복잡도가 증가하면서 정상 데이터의 복원 능력이 과도하게 향상되어, 일부 애매한 비정상 패턴까지 정상 범주로 판단했을 가능성을 시사한다. 현재까지의 실험 결과를 종합했을 때, Anomaly Recall과 Precision의 균형이 가장 좋았던 EMBEDDING_DIM=16, LATENT_DIM=16 조합 (exp-20250814-182752)이 가장 안정적인 성능을 보이는 것으로 판단된다.

---

### exp-20250814-182752: LATENT_DIM 16 성능 측정 (25/08/14)
- **커밋 해시:** `450adff`
- **가설:** 정보 병목 구간인 잠재 벡터(LATENT_DIM)의 차원을 8에서 16으로 늘리면, 모델이 정상 데이터의 복잡하고 다양한 패턴을 더 풍부하게 인코딩할 수 있게 된다. 이렇게 정상 데이터에 대한 표현력이 증가하면, 정상 데이터의 재구성 오류는 전반적으로 감소하고, 정상 패턴에서 벗어나는 비정상 데이터의 재구성 오류는 상대적으로 더 두드러지게 나타날 것이다. 결과적으로, 모델의 전반적인 변별력(AUC)과 탐지율(Recall)이 개선될 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 16
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7873
  - Anomaly Recall: 0.6222 (비정상 데이터 중 62.2%를 탐지함)
  - Anomaly Precision: 0.9046 (비정상이라고 예측한 것 중 90.5%가 진짜 비정상)
- **결론:** 가설대로, LATENT_DIM을 16으로 확장한 결과 Anomaly Recall이 0.61에서 0.622로 소폭 상승하며 긍정적인 효과를 보였다. 이는 모델이 정상 패턴을 더 잘 학습함으로써 비정상 패턴을 더 효과적으로 구분해냈음을 의미한다. Precision 또한 0.905로 높은 수준을 유지하며, F1-Score와 AUC 모두 Baseline 대비 개선되었다. 이전 LATENT_DIM=4 실험과 비교했을 때, 정보 병목을 너무 강하게 압축하는 것보다 적절히 확장하는 것이 모델 성능에 더 유리함을 확인했다. 따라서 LATENT_DIM=16은 Recall과 Precision의 균형을 유지하며 전반적인 성능을 향상시킨 성공적인 튜닝으로 판단된다.

---


### exp-20250814-181431: LATENT_DIM 4 성능 측정 (25/08/14)
- **커밋 해시:** `450adff`
- **가설:** 정보의 병목 구간인 잠재 벡터(LATENT_DIM)의 차원을 8에서 4로 대폭 줄이면, 모델은 정상 데이터의 가장 핵심적이고 일반적인 특징만을 압축하도록 강요받을 것이다. 이 과정에서 비정상 데이터에만 존재하는 특이한 정보들은 압축 과정에서 손실될 확률이 높아져, 복원 시 재구성 오류가 더 커지게 된다. 결과적으로, 비정상 데이터를 탐지하는 능력(Recall)이 향상될 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 4
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7880
  - Anomaly Recall: 0.6175 (비정상 데이터 중 61.7%를 탐지함)
  - Anomaly Precision: 0.8809 (비정상이라고 예측한 것 중 88.1%가 진짜 비정상)
- **결론:** 가설과 유사하게 Anomaly Recall이 0.61에서 0.618로 소폭 상승하여, 더 강력한 정보 압축이 일부 비정상 탐지에 긍정적인 영향을 미쳤음을 확인했다. 하지만, 이는 Precision이 0.90에서 0.88로 더 크게 하락하는 대가를 치렀다. 이는 과도한 정보 압축으로 인해 일부 정상 데이터의 복원 능력까지 저하되어, 정상을 비정상으로 오탐하는(False Positive) 경우가 늘어났음을 의미한다. F1-Score와 전반적인 성능 균형을 고려했을 때, LATENT_DIM=4는 Recall 개선 효과보다 Precision 하락의 부작용이 더 크다고 판단된다. 따라서 기존의 LATENT_DIM=8 설정이 더 안정적이고 우수한 것으로 결론 내린다.

---

### exp-20250814-175958: EMBEDDING_DIM 32 성능 측정 (25/08/14)
- **커밋 해시:** `450adff`
- **가설:** 임베딩 차원을 16에서 32로 늘리면, 모델이 각 location_id와 event_type의 미묘한 의미 차이를 더 풍부하게 학습할 수 있게 된다. 이 향상된 표현력은 정상 시퀀스의 복원 능력을 높여 전반적인 재구성 오류의 분포를 안정시키고, 결과적으로 비정상 시퀀스와의 변별력(AUC) 및 탐지율(Recall)을 개선할 것으로 기대한다.
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 32
  - `LATENT_DIM`: 8
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7866
  - Anomaly Recall: 0.6201 (비정상 데이터 중 62.0%를 탐지함)
  - Anomaly Precision: 0.9156 (비정상이라고 예측한 것 중 91.6%가 진짜 비정상)
- **결론:** Anomaly Recall이 0.61에서 0.62로 소폭 상승하며, 더 많은 비정상을 탐지해내는 긍정적인 효과를 확인했다. AUC 또한 미세하게 상승하여 모델의 전반적인 변별력이 개선되었음을 시사한다. Precision이 약간 감소했지만, 0.916이라는 여전히 높은 수치를 유지하며 신뢰도를 확보했다. 따라서, EMBEDDING_DIM=32는 현재 모델의 성능을 한 단계 끌어올린 성공적인 튜닝으로 판단되며, 이를 다음 실험의 새로운 베이스라인으로 채택한다.

---

### exp-20250814-172309: EMBEDDING_DIM 8 성능 측정 (25/08/14)
- **커밋 해시:** `450adff`
- **가설:** 벡터의 차원이 줄어드는 것이니 일반화하기 좋지만, 세부 특징은 놓칠 수 있음
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 8
  - `LATENT_DIM`: 8
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7864
  - Anomaly Recall: 0.5966 (비정상 데이터 중 59.7%를 탐지함)
  - Anomaly Precision: 0.9574 (비정상이라고 예측한 것 중 95.7%가 진짜 비정상)
- **결론:** Recall 안 좋아졌지만 비정상 예측은 좋아짐

---

### exp-20250814-165527: Baseline 모델, 초기 파라미터로 성능 측정 (25/08/14)
- **커밋 해시:** `ffc7025`
- **하이퍼파라미터:**
  - `WINDOW_SIZE`: 3
  - `EMBEDDING_DIM`: 16
  - `LATENT_DIM`: 8
  - `BATCH_SIZE`: 64
  - `EPOCHS`: 50
- **결과 분석:**
  - AUC: 0.7845
  - Anomaly Recall: 0.6088 (비정상 데이터 중 60.9%를 탐지함)
  - Anomaly Precision: 0.9007 (비정상이라고 예측한 것 중 90.1%가 진짜 비정상)
- **결론:** Anomaly Recall을 높이는 방향으로 진행해야 할 듯

---